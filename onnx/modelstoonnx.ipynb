{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a1559d-bc98-4dfb-852f-4c9ffef48e86",
   "metadata": {},
   "source": [
    "# PKL to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c0b0e-8426-44b4-b486-23495c90c99f",
   "metadata": {},
   "source": [
    "!pip install onnx_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5feeae-8f03-4e5f-9ef7-6029040dd170",
   "metadata": {},
   "source": [
    "!pip install skl2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e677c9f4-06a6-4382-ab1e-c894969b07fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import skl2onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# Load the scikit-learn model from the pickle file\n",
    "with open('ocsvm_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Define the initial input types\n",
    "initial_types = [('input', FloatTensorType([None, 4]))]\n",
    "\n",
    "# Convert the scikit-learn model to ONNX format\n",
    "onnx_model = skl2onnx.convert_sklearn(model, initial_types=initial_types)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "with open('ocsvm_model_pkl.onnx', 'wb') as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e3752-4484-4e96-b16f-9b6db561770a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63fae6-b251-43bc-9fbd-a0e60e088e23",
   "metadata": {},
   "source": [
    "# H5 to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485aa15d-c0a0-4d22-985d-5b90a13efa42",
   "metadata": {},
   "source": [
    "!pip install tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83a4e915-aaf9-47a4-b6af-41cd9cf7c14c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "2023-04-07 17:59:38,758 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "c:\\Users\\ssarangi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\keras\\backend.py:431: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2023-04-07 17:59:39,840 - INFO - Using tensorflow=2.12.0, onnx=1.13.1, tf2onnx=1.14.0/8f8d49\n",
      "2023-04-07 17:59:39,840 - INFO - Using opset <onnx, 15>\n",
      "2023-04-07 17:59:40,104 - INFO - Computed 0 values for constant folding\n",
      "2023-04-07 17:59:40,104 - INFO - Computed 0 values for constant folding\n",
      "2023-04-07 17:59:40,153 - INFO - Computed 1 values for constant folding\n",
      "2023-04-07 17:59:40,177 - INFO - folding node using tf type=StridedSlice, name=sequential/lstm_1/strided_slice_1\n",
      "2023-04-07 17:59:40,248 - INFO - Optimizing ONNX model\n",
      "2023-04-07 17:59:41,460 - INFO - After optimization: Cast -5 (10->5), Concat -1 (2->1), Const -24 (70->46), Expand -1 (2->1), Identity -30 (31->1), Placeholder -1 (11->10), Reshape -1 (2->1), Squeeze -1 (4->3), Transpose -2 (5->3), Unsqueeze -4 (6->2)\n",
      "2023-04-07 17:59:41,476 - INFO - \n",
      "2023-04-07 17:59:41,476 - INFO - Successfully converted TensorFlow model C:\\Users\\ssarangi\\onnx\\saved_model.h5 to ONNX\n",
      "2023-04-07 17:59:41,476 - INFO - Model inputs: ['embedding_1_input:0']\n",
      "2023-04-07 17:59:41,476 - INFO - Model outputs: ['Identity:0']\n",
      "2023-04-07 17:59:41,476 - INFO - ONNX model is saved at model_h5.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --keras C:\\Users\\ssarangi\\onnx\\saved_model.h5 --output model_h5.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df68bf-51f2-4f23-84be-7493681bc265",
   "metadata": {
    "tags": []
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578be59c-2e6b-4b8e-95ec-2eb1cfa8c813",
   "metadata": {},
   "source": [
    "# PB to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a84fd-ee83-410b-a03e-6ddc93b7b871",
   "metadata": {},
   "source": [
    "!pip install tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1764d94c-8f9d-4dd8-8d51-df1583373fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "2023-04-07 17:59:48,754 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2023-04-07 17:59:48,772 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2023-04-07 17:59:49,105 - WARNING - Importing a function (__inference_pruned_7112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2023-04-07 17:59:49,865 - INFO - Signatures found in model: [serving_default].\n",
      "2023-04-07 17:59:49,865 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2023-04-07 17:59:49,865 - INFO - Output names: ['output_0']\n",
      "2023-04-07 17:59:53,911 - INFO - Using tensorflow=2.12.0, onnx=1.13.1, tf2onnx=1.14.0/8f8d49\n",
      "2023-04-07 17:59:53,911 - INFO - Using opset <onnx, 15>\n",
      "2023-04-07 17:59:54,296 - INFO - Computed 0 values for constant folding\n",
      "2023-04-07 17:59:54,766 - INFO - Optimizing ONNX model\n",
      "2023-04-07 17:59:56,514 - INFO - After optimization: Add -7 (17->10), Cast -6 (6->0), Const -92 (236->144), Identity -2 (2->0), Transpose -126 (130->4)\n",
      "2023-04-07 17:59:56,662 - INFO - \n",
      "2023-04-07 17:59:56,662 - INFO - Successfully converted TensorFlow model C:\\Users\\ssarangi\\yolov5\\runs\\train\\rust_100\\weights\\saved_model to ONNX\n",
      "2023-04-07 17:59:56,662 - INFO - Model inputs: ['x']\n",
      "2023-04-07 17:59:56,662 - INFO - Model outputs: ['output_0']\n",
      "2023-04-07 17:59:56,662 - INFO - ONNX model is saved at model_pb.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --saved-model C:\\Users\\ssarangi\\yolov5\\runs\\train\\rust_100\\weights\\saved_model --output model_pb.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac20ef-ca61-48f2-b0ab-b3821e4eac32",
   "metadata": {
    "tags": []
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055aee6a-6990-43b1-b53d-20efe76a39ba",
   "metadata": {},
   "source": [
    "# PT to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586cf511-aac3-4515-9868-55fc47bc6d89",
   "metadata": {},
   "source": [
    "!pip install tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8be064f-1ff0-4bc7-83cb-0e06202eddbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=C:\\Users\\ssarangi\\onnx\\data\\coco128.yaml, weights=['best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "YOLOv5  2023-4-3 Python-3.11.2 torch-2.0.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7029004 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from best.pt with output shape (1, 25200, 12) (13.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.1...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.3s, saved as best.onnx (27.2 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\ssarangi\\onnx\u001b[0m\n",
      "Detect:          python detect.py --weights best.onnx \n",
      "Validate:        python val.py --weights best.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'best.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights best.pt --include onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405f1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
